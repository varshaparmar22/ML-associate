-Glue ==== de-duplication === ml feature

-network latency ==== outside aws environment latency(user to sm endpoint vice-versa)

-overhead latency  ==== inside was environment latency (sm endpoint to model container vice-versa)

-conditioned disparcity ====> condition should be followed to check

-logloss = quality of probability of output, 0 is best, costfun in logistic regre,===
specify model make incorect prediction with high probability. binary & multiclass model

-lineage tracking === which dataset, training job, Hp etc. are producing given model - 
auditing & reproducibility

- sm pipeline=== contional steps can be added, this or that

- lambda = lightweight models only can be deployed not recommandation kind

- transparent model = how input convert into output ==== optimization should be transparent 

- sm script mode == 1.install custom lib(if any) 2. use your training script, requirement.txt, model code
3. use sm's prebuit container with above setup to launch container on endpoint

- Sm pipeline has callback step for glue, for emr direct step is there, many other steps are there too

- varying traffic --- auto scaling

- choose report, alert if only they are specified to implement

- attach the tag for cost management:(tag can be aws/user generated but tie up to cost allocation is 
must in each)
1. create tag, 
2. attach tag to resource, 
3. tie up those tag in cost allocation

- Parquet : big data, columnar, binary, splittable, fast query, data compression, encoding, optimized for analytics

- avaro : serialization

- Credit bureau data : check person's financial behaviour

- Fsx for luster : sub milisec latency, hundreds of gigabytes/sec tp, millions of IOPS, high computing, 
parallel, large dataset, sequential & random access

- KDS : data ingestion/storage

- MSAF : processing, transforming, filtering, enrichment(like with sql)

- KDF : ingestion & deliver -  no retension

- Kafka : mainly use for transfering real-time data between apps & systems

- pattern/comparison => bar plot(bar/pattern)

- distribution/frequency/count => histogram (fd/hist)

- Concentration & distribution in continuous range => density plot

- pattern/trend => heatmap

- bedrock provide unified api, not distinct api for fm. means one api just chane fm id to get access

-  private customization=> fine tune FM as per need

- multi-colinearity : statical approach to check co-relation between feature not visualization

- TVD : [[[[maximum divergence/disparcity]]]] in outcome distribution between diff demographic group

- KUllback liberal divergance : divergence between 2 probability, compare outcome distribution across diff group

- EFS : not provide low latency and high TP

- snowcone : 14 tb, snowball : 100 tb, snowmobile : 100 Pb

- Amazon S3 Transfer Acceleration : use optimized network protocols and AWS cloudfronts's edge locations, 
acc s3 transfer - accelerate uploads to Amazon S3 over long distances

- Parquet = structured and semi-structured data, NOT unstructured data. NOt for realtime data processing

- JSON line === when want to handle unstructured data like image, video, audio --- one single line on 
each line can be parsed

- JSON === wont improve processing performance as it has hierarchical structure

- shard provides a fixed amount of throughput, add more shard to handle high volume of data fast - 
improve ingestion performance and reduce latency
- high latency low tp -=== try increase shard   <==== KINESIS

-AWS Global Accelerator : static IP add, improving the availability and performance of applications 
by routing user traffic through the AWS global network infrastructure. Traffic accelerator. 
Rout traffic to that endpoint which is hosting app

- AWS DataSync : use for data migration, on-premise-aws -- online tool

- SCPs = guardrails on actions, a user or role can do. -  SCPs as master guardrails or account-wide permissions 
boundaries. - service control policy --- organisation based - IAM is not matter here

- AWS Resource Access Manager (RAM)  = cross account resource access

- execution roles are crucial for granting the required permissions for SageMaker components to 
interact with other AWS services, such as Amazon S3

- inline policy : to specific thing give permission, like particular domain, in sm studio many domains can work
together - when dont want to conflict with anything

- visual tool : minimal operational effort

- Virtual Drift in model : only when infrastructure or deployment changes.

- Access Denied error = 403

- 401 Unauthorized:MissingAuthenticationTokenException

- 400 Bad Request: IncompleteSignatureException, ValidationException, InvalidAction

- IAM role be assumed by entities (users, applications, services), temporary access short term

- access across account ==== cross account access is must

- S3 Access Points : associated with network path & will need IAM role to assign access to s3 to someone

- execution role is IMP for notebook, domain, ec2 instance to do some task

- IAM policy attached to user --- user will have access to everywhere not domain specific

- policy attach to role --- give access to all users which are using that role outside of domain too

- policy attached to IAM group  --- give access to all users from given group so user from it can be 
outside domain one too



+======================================================================================

-variant === testing new model-

- sm pipeline === UI drag n drop

- in spot training ==> MaxWaitTimeInSeconds must be larger than MaxRuntimeInSeconds

- Accelerated computing group of ML instances : g,p family - has hardware accelerator. 
for ML, Deep Learning, when real-time/near real-time need - graphics rendering, machine learning, 
and data-parallel computations

- High-performance group : CPU based - scientific modeling, web-scale applications, or batch processing, c

- Memory-optimized group :  in-memory databases or big data analytics. r,x,z 

- General-purpose instances : web servers, development environments, and databases, balanced of compute, 
memory, and networking, t,a,m

- storage optimized : big data workloads, NoSQL databases, and distributed file systems, i,d

- sm Model Monitor to analyze the training data and generate a baseline of statistics and constraints.

- Data wrangler + SM Data preprocessing  (feature engineering + data preprocessing-scheduling and 
executing processing task) good combo

- Direct connection : on-premise + aws

- PrivateLink = private connection between(vpc+aws) no internet === use aws network


- validation:ndcg == ranking metric for ranking tasks, such as search engine results

- model giving wrong prediction in evaluation/training === clarify can help to identify issue

- Amazon SageMaker Clarify => why your ML model made a specific prediction and bias impacted this prediction
during training or inference help to mitigate that issue, generate report too === 
CreateProcessingJob api, SageMaker ClarifyProcessor for that processing job

- CreateModelInvocationJob : for batch inference job in Bedrock 

- Debuggeer can detect : overfitting, class imbalance, vanishing gradients, or divergence -  during training

- realtime monitoring in training =======> debugger

- TensorBord : visualization, analyzing = accuracy, loss, gradient while training but 
it is manual to check not automatic as debugger

- Debugger & TensorBoard ===== SAME ====== Debugger(atomatic),  Tensorboard(manual)

- lambda : execution duration (15 minutes max) and payload size (6 MB for synchronous and 
256 KB for asynchronous invocations).

- serverless : 4 --- 60 sec

- realtime : 6 ----- 60sec - realme6pro

- async : 1gb----60min

- batch : 100mb

- custom ML logic into an existing Amazon SageMaker Pipelines workflow => @step decorator 

- TransformStep : for data/batch transformation not anyother

- @remote : remote fun call, throw u outside pipeline

- SM training : s3, EFS, FSx for luster

- customized Bedrock model : purchasing Provisioned Throughput is necessary - before using model for 
real purpose

- Knowledge Base : 1. RAG app   2. Agent
  1.RAG app : RetrieveAndGenerate  api => retrive from KB and generate response
  2.RAG app : Retrieve api => retrive (direct query) from KB
  Agent :  reason through steps to assist 

- multi-modal + a/b testing  is possible

- TPR, FPR ==== true and false will chnage in formula only, p,n will be at same place ======== ROC curve

- TNR, FNR ==== true and false will chnage in formula only, p,n will be at same place

- using VPC only:(to connect notebook to comprehend kind)
  Notebook instance === in === private subnet & has access to vpc endpoint ==== (PrivateLink) ==MUST

- Security Group ==== in/out bound traffic control
- Top P => higher => less likely o/p => 0.8 means pool having 80% tokens to choose from, 0.1 means 
10% to choose from == % of pool size

- K == pool size

- Macie = ==== = only s3 related, not other direct data like from textract

- SM savings Plan : service to save cost on SM resource - 1-3 years commitement = optimize ML cost in SM - 
direct helpful - no visualization and analysis

- Titan (text=>text gen), (image gen=>texttoimage gen), (text embedding=>embedding), 
(multimodal embedding=>text, image embedding)

- QuickSight ML Insights => ML-powered anomaly detection, ML-powered forecasting, and 
Autonarratives enhance dashboards.

- ElasticSearch => search-based analytics and indexing, not for ML, for log or text search

- Mchanical Terk ==> associate GT(inbuilt recruiting, training, and monitoring), scalable n efficient

- Model optimization techniques = quantization, compilation, and automatic model parallelism, 
inference latency and throughput.

- ModelExplainabilityMonitor  class: create shap baseline value, monitor will check against 
feature attribution value n alert if any deviation, model begins to emphasize one input over other

- SHAP baselines = create an explainability baseline for how each feature should contribute to the 
model’s predictions.

- bias : steady input which effecting output.

- ModelDataQualityMonitor  : track quality and distribution not attribution towards prediction

- ModelPerformanceMonitor : track performance of model

- FastFile mode ==== Images, audio, video

- Pipe mode ======= CSV, JSON, logs

- Bert based NLP model==== need parallel access to data from file, pipe mode works sequential base while, 
FF mode = parallel base, so FF

- ML type          CV, NLP (large files)==> FF...........  Tabular/structured ML ==> Pipe

- in FF --- start up is fast, but training data will be stored on training instance gradually so that
much space will be needed

- Amazon SageMaker Processing jobs, aws step function : serverless environment

- lambda = short lived, not suitable for ML data processing (long task) - execution time limitation, 
6mb payload size

- apache airflow === having server

- step scaling : predefined thresholds of metrics like CPU utilization

- Density estimation  : distribution of a continuous variable, like purchase amounts

- residual plot = biased, underfitting, or overfitting the data.

- AWS Glue = structured and semi-structured data

- Wrangler == text, image or any data

- user feedback is imp for improving prompt engineering

- in RAG accurate & contextually relevant answer => prompt engineering

- RLHF - Reinforcement Learning with Human Feedback (RLHF)

- SM training : s3, fsx for luster, efs only

- sample_size = 100 in KNN ===> all instance will divide data from 100

- To schedule pipeline by eventbridge
1. create pipeline
2. create rule for eventbridge
3. schedule pipeline by event bridge rule

- 2 variables ===== correlation/relationship/trends with anomaly === scatter


- Heatmap= intersection of 2 dimension

- CT data event ::::: Bedrock ::::: 1. Bedrock agent alias, 2. Bedrock knowledge base = resource level action 

- model registery : Attach metadata, such as training metrics, dataset, hyper parameters to each model.

- check tensors with tensorboard in cnn training

- ensure reproducibility of result === randomseed === 25 kind(same sequence of 25)

- Spark ML container/sci-kit learn container for data processing in inference pipeline

- Async inference ====== can be batch transform/inference

- customer churn===logistic regression ==== dont fall for probability of model to predict === distractor

- hyperband- minimum computation time, its parallel, early stopping, dynamic resource allocation

- after update if data quality down in model monitor , set new baseline of model

- model quality => retrain model with new data

- Strong correlations may indicate redundant variables, while weak correlations may signal the need for 
additional features or data transformations.

- cost allocation tag is feature in cost and billing management

- cut-off means threshold

- high Precision => low false positives & high Recall => high true positive rate

- Cloud watch log insight : in-depth log analysis - sql query engine, visual too 

- QS has basic forcasting capability, not data preparation

-  Amazon Managed Service for Apache Flink: perform real-time data transformations, filtering, and enrichment

- Amazon Comprehend Custom Entity Recognition - domain specific sdata key word extraction

- Opensearch => searching & indexing data, vector database, vector search for RAG

- SM Debugger: debug training, identify memory, compute usage, training issues like overfitting, 
vanish gradient, under utilized resource, under performing jobs, analyse the metrics and offer 
recommendation like reduce resource consumption, identify bottlenecks, and improve training process, 

- aws traininum : sustainability, low envornmental footprint

- we have model made focus on training ===== now make sustainable by debugger & trainium, 
- AMT can do work while model development not after that

- During training need to implement sustainability ===== CHoose Debugger

Amazon SageMaker Edge Manager : deployment, monitoring, and maintenance of models on devices at the edge

- in Model registery model group --- logical collection of model version --- same problem/usecase

- in sm multi-modal - infrequent used model will have little latency issue as it need to load in memory 

- sm estimator === to train machine learning model - define & execute training process

- for manual approval workflow -- need code to do by python Boto3 to approve model, registery to get 
version of model, pipeline for condioned deployment

- in CF aws::SageMaker::Model === create model ---- specify all model properties tag, contaienrs, 
primarycontainer, enablenetworkisolation, executionrolearn, modelname, vpcconfig, inferenceexecutionconfig etc

- in CF aws::SageMaker::Endpoint  => to create endpoint, aws::SageMaker::EndpointConfig  => to create
related endpoint configuration
other are ModelPackage, Project => respectively manage version & manage project in SM

- clarify during development and monitor after deployment useful for bias detection

- to use modal in canvas => register model in model registry, give access to s3 bucket where it is 
stored to canvas user

- Amazon SageMaker JumpStart offers pretrained, open-source models for various types of problems, 
executable example notebooks 
 fine-tune these models before deploying

- remove columns from ds will be easy with columnar format data like parquet

- Model registry COLLECTION = to categorize model into diff types

- max_depth in XGBoost - reduce to reduce overfitting ====== reduce overfitting in xgboost= generalize better 

- Production variant : behind single endpoint deploy multiple models/version of model

- Concept drift occurs when the statistical properties of the target variable, which the model is
trying to predict, change over time in unforeseen ways

- glue's findmatches capability will detect duplicats flag n merge records too

- Transcribe can process audio n video files

- Jurrasic ===> NLP ==> summarization, text generation, sentiment analysis

- High Recall ==========  positive ---positive & Ok little FP

- High Precision =========== positive ---positive & Ok little FN

- Managing EC2 auto scaling is bad choice. 
- Use serverless with provisioned concurrency when you need low latency/real-time workload to handle,
traffic burst is there
- low-latency is required dont choose asynchronous 

- Provisioned Concurrency usage, based on the      memory + duration + level     of concurrency enabled.

-LighGBM - gradient boosting ML, like XGBoost...mainly all features from XGBoost it has... 
complex relationship between features, 
mainly it is cpu based training with single/distributed. N cpu inference. handle both type of 
data like categorical n numerical &
large-scale data 

TabTransformer : tabular data, (transformer archi + embedding ) for categorical variables

Factorization Machine is ===sparse dataset.... if model has complex relationship between variables 
it can not go


Min-Max Normalization = (x – min) / (max – min)
- Use the min-max normalization statistics derived from training data to normalize the incoming sales data.


- Serverless ==== handle low/high/no traffic very well, auto scaling, 
 MaxConcurrency =1 means maximum request model can handle at once.. so sequentially handle all request.
 ensures efficient handling of traffic bursts during peak periods while minimizing costs in low-traffic 
periods so kind of realtime inference it can give


- ASYNCH IS NOT REALTIME........ go for SERVERLESS == REALTIME

----- Fluctuating traffic ========== go for  =========SERVERLESS
- asyn for batch inference


 SageMaker Studio Classic : building, training, and deploying , monitoring === all type of deploying

- interruption === spot instances

- ImportModel feature= cross account usage of model with required permission like resource basedIAMpolicy

- on-premises infrastructure and AWS communication ==== direct connect

- import your data from S3 using the schema detected by AWS Glue. Use the Data Wrangler’s built-in
transformations to clean and format your data. & save data into s3 back
when glue n data wrangler is there ----- wrangler will be best choice in many circumstances

- regularization adds a penalty to large weights, encouraging simpler models.

- Smaller batch sizes can introduce more noise into the training process

- Amazon SageMaker Model Registry is a feature of Amazon SageMaker that provides a centralized repository 
for organizing and managing machine learning models within an organization(having many account).

- If clearly only recommendation required for compute instances then go for AWS compute optimizer ---
it will check configuration, metrics of resources n give recommendation, it use ml too so give more 
precise result--- ECS, E2, EBS, lambda(EKS cluster inside use ec2 instances)
uses machine learning to analyze historical utilization patterns and provide actionable recommendations 
for optimizing AWS resources

- Trusted Adviser ===  not primarily designed for containerized workloads or ML model applications. 
It offers more general cost-saving advice across various AWS services.

- Kendra search serving --- 
use ml, 
do indexing, 
do semantic search, 
improve search result overtime by ml
document security by access controls

Amazon Kendra S3 connector is special service to connect s3 with kendra -  full and incremental 
synchronizations from S3 to Kendra to keep the search index up to date. 

- blurring image will not improve model accuracy... it will reduce noise, protect privacy in image
- DW image features : resize image, rotate, flip, Enhance Image Contrast, Blur
- to improve model on not clear images prediction === use enhance image contrast- gamma correction, 
enhance low quality images

- if categorical feature has unique interdependency with each-other and other numerical features then 
use encoding on categorical feature to capture it well

- mainly in all models need to convert categorical data ===== > numeric data

- blocked/filter feature to filter out response from gen ai q business chatbot

- FSx for luster is Linux based file system

- robust scaler === use when outlier is there. Remove median from given value n scale data by interquartile 
range (IQR) -- p25,p75
- standard scaler --- remove mean(effected by outlier) and scale data by standard deviation
- z-score normalization --- scale feature value to unit norm -1,0,1

$$$ CSV to Parquet = to prepare data for ml

# Save as Parquet with optional compression (Snappy is default)
df.to_parquet("your_file.parquet", compression="snappy")

1. remove irrelevant columns
2. convert into parquet
3. do compression

for performance improvement

- Big data processing === EMR  ===== distributed computing framework

- Detecting-Redacting PII/PHI is not to create from code... use aws services for it or 
prebuilt model(canvas or some) to achieve it

- with lambda === configuring, deploying, maintaining are associated so its not minimal operational overhead
- converting pdf to text will increase operational overhead too

- Feature is change =====> output of model is change ==== partial dependency plot
  pdp ====visualize marginal effect of one /more features on prediction

- TVD = overall difference between two probability distributions.

- Kullback-Leibler Divergence (KL) = difference between two probability distributions.

- Spearman === man===not normal, non-linear relationship between numerical features
- pearson ==== son ==== linear-relationship ==== normal distribution

- for time-series/ordered data(sorted by order) === we need to preserve order ==== split in dw by Ordered
split
- dw === ordered/keybased/randomized/stratified === split type

Blue/green deployment : two model/model variant deployment, having auto rollback feature
canary : small portion traffic shift and monitor it and them ramp it up


- Custom Python script for processing for model: create container with script n add all dependencies, 
push to ECR n use it as PROCESSING container
- in BYOC you have to create container with all dependency. if want to use benefits of prebuilt container
then extend them in your container and use script mode.The custom Python scripts must be packaged and 
executed within a container or computing environment.


Processing Job
new data s3 => s3 event notification => trigger lambda => sm processing job calling => result in s3

- Batch : schedule task like once daily, not realtime need, a few minutes to several hours or even days 
can take too

- scaling occur very rapid change in cooldown pariod

- gateway endpoint within the VPC : Amazon S3 and DynamoDB within the same region. 

- interface endpoint within the VPC : cross region

- AWS Transfer Family not intend to integrate directly with SageMaker for training across regions.

- Model card : information about each model, including its background, intended use cases, 
performance metrics, and business context.

Bedrock to fine tune model
1 create Hp tunning
2. analyse result - training & validation
3. purchase provisioned throughput for deploying it on endpoint to work- before using this in bedrock task
model should be fine tunned and provisioned first

creating knowledge base
1. create bucket
2. create(configure) knowledge base in bedrock
3. load data in knowledge base

configure data source & configure vector source N create

- Object detection == identify and locate multiple objects within an image === counting specific items, 
such as animals, in drone imagery

- Semantic segmentation algorithm  == autonomous vehicles to identify road signs and medical imaging, 
give each thing, give label to each object in image 
- boundry/area/segment in image ==== semantic segmentation
- presence/location in image === object detection
- Image classification algorithm   single/multi label to entire image

- To update Feature Group : 
1. use UpdateFeatureGroup to add new feature(attribute) in group,
2. PutRecord to update all new/old record (data populated) with attribute value of new feature

reindexing will not update-- need to use putrecord to update old/new records for values

- To minimize false positive ==== minimize False Positive Rate

- High performance === high compute power

- Accelerated Computing === GPU - deep learning inference and model training.

- if ML pre-processing is required like pre-processing, feature engineering, splitting etc === go for Sm 
pre-processing if in option
  not Glue ---- as glue is for normal ETL process, not ml specific

- CreateModelInvocationJob======== for batch job in bedrock
- InvokModel ======== just invoke model for inference (single)


SM Debugger : detects errors, bottlenecks, or other inefficiencies during the training process,
automatically generate alerts when anomalies or specific conditions, such as class imbalances or overfitting, 
occur during the training
 minimizing operational overhead === use debugger == realtime, automated

- TensorBoard : visualizing training metrics such as accuracy, loss, and gradients- manual to do

- Sporadic inference need --- async - handle cold start problem

- Notebook instance in === VPC endpoint & aws service in === VPC endpoint --------- they will be connected by 
Privatelink(interface endpoint)
Notebook instance MUST be in Private SUBNEt to connect to aws service in VPC with proper permissions

- AWS Billing and Cost Management : monitor, manage, budget, billing alert

- ModelExplainabilityMonitor leverages SHAP (Shapley Additive Explanations) values to track the contribution
of each feature.

- auditing + tracking API calls + compliance + monitoring across multiple services -CloudTrail

- 1. create pipeline, 2. Create role, 3. Schedule BridgeEvent   ==== schedule pipeline execution

- for gaming server compute optimized (high performance instance) will go, for ML use acc computing

- big data analytics = operation in memory == memory optimized

- check work monitoring to select cloudwatch log/alert/insight === apps, service, system related 

- audit/compliance/log === cloudtrail === api call related 

- scatterplot is ideal for visualizing the relationship between two continuous variables

- Based on user query search is there is the - semantic search

- TensorBoard show you each n every layer result of NN network so to check tensors it will be easy with it
  converging, or vanishing or exploding weights and gradients, accessing tensor data, compare multiple
training jobs Debugger is not visual

-  random seed ensures that the tuning job generates the same sequence of random numbers across multiple runs,
leading to consistent and reproducible results. 

- SM AUTO-PILOT == do only -----SUPERVISED TASK. having label is must

- Inference pipeline work for realtime/batch inference

- AMT is Hyperband, a multi-fidelity tuning approach

-  AWS Trainium supports popular ML frameworks such as TensorFlow, PyTorch, and MXNet. 

- AWS Trainium is a purpose-built instance(microchips) type

With Model Monitor, you can establish:

– Continuous monitoring with a real-time endpoint.

– Regular monitoring through batch transform jobs.

– Scheduled monitoring for asynchronous batch transform jobs.

- Tabtransformer === tabular data handling, categorical & numerical data n associate with their embedding

- Amazon SageMaker Studio Classic -- workflow can create - building, training, and deploying & monitoring 
machine learning models
- AWS glue can create data ingestion pipeline too --- ETL

- Amazon Q Business==== name as a 'blocked word', the service can automatically omit it from the chatbot’s 
responses.

- EFS is only for Linux instances only --- 

- Mechanical turk -==== ANY human task
- ground truth ==== data labeling ---- incorporate with mechanical turk, private companies, 

- SM interleaved pipeline for model parallelism for tensorflow and pytorch

- Sm Model Parallelism library only work for PYTORCH

- Sharded Data Parallelism ====  Data Parallelism(calculation of gradient) + model Parallelism(calculation of weight & activation layer)
  implemented in sm model parallel library for pytorch only === already there in DLC of pytorch

- Training accelerator device for training -- Elastic fabric adpter = network device  = can attach to instance =
  use maximum bandwith and use nvidia collective communication library

- MISC - minimize communication scale --- p4de GPU instance(400 gbps networking, 80gb memory)

- Trn1  == 800 gbps networking, Trn1n  == 1600 gbps networking 

- deploy models by : 
 1. ModelBuilder from the SageMaker Python SDK - by code
 2. SageMaker JumpStart : pre trained model on pre configured endpoint
 3. Cloud Formation 

Boto3 ======= raw access to AWS APIs. any aws service can be accessed
exa= CreateTrainingJob, CreateEndpoint

SageMaker Python SDK ==== built on boto3 === high level library for working with SM === mainly for ML = training,tunning,deployment
hides all low-level API calls.  training, model uploading, deployment, tuning== can even do local testing 
ex = estimator.fit(), predictor.predict()

If you want maximum flexibility (custom configs, fine-grained networking, special resource setups), go Boto3.
If you want to quickly train/deploy models without worrying about API structure, go SageMaker Python SDK.

ALB == Web apps, API gateways, microservices routing, path-based routing.
NLB == IoT apps, gaming, real-time systems, highly sensitive latency apps. HIGH TP


cloudwatch containers insight : for log, metrics of container like EKS, ECS

cloudformation+infrastructure composer === visualize cf

- cloudwaTCH alarms are based on metrics, not log

- A C - trail can be applied to All Regions (default) or a single Region.
Management Events:
• Operations that are performed on resources in your AWS account

- AWS config can use eventbridge/sns direct to send notification about compliance state/config change
- SM jumpstart has built in fine tunning functionality, bu js you can compare, evaluate fm models based 
on their pre-defined quality and metrices
- Stacking involves training a meta-model on the predictions of several base models
- fine tunning feature is available in sm jumpstart
- in sm script mode : === 1. Your training script (train.py) 2.Any dependencies (optionally via requirements.txt)
3. choose a prebuilt SageMaker container (e.g., pytorch, tensorflow, etc.). No custom container needed
- SAM & lambda is associated, lambda is pay per use, realtime, serverless, event driven, lightweight, 
use with api gateway/event driven, auto scaling,
- SAM - serverless application model framework - use yalm scrpt to specify security n othr config
- if model is suffering from latency/performance issue while request == check X-ray to debug
- production variant/ a/b testing : behind same(one) endpoint multiple model will deployed 
- parquet : large dataset, parallel proessing as column based, nested structure, array kind storage
- data validation - in canvas new feature to check data quality
- cost report can be filter by resource tag, need to activate tag in 'cost allocation tag' section first
- auto scaling related budget alert can be set too
- dont want to manage infra === go to serverless
- LF tag access control --- feature - to assign acc control on lf data catalog for the retriver of LF
- custom workload, manual approval step, lambda step, emr, glue to run in sm pipeline - it will require role
- DW has data quality & insight report to chek data quality & abnormality - help you to 
clean and process data, warning to investigate and make transformation according to that
- compute optimizer check metrics and configuration of resource and give the recommandation
- All resources that the user profile creates will have a domain ARN tag and a user profile ARN tag. 
- budget can be set = based on ml cost/tag based resources - u can specify tag name to set bud
- ACL are not secure.. use role n bucket policy for access control
- parameter store will not give secret rotation, secret can be versioned in secret manager
- managed rotation are for : Amazon Aurora, Amazon ECS, Amazon RDS and Amazon Redshift. in S M
- async & realtime ==== persistant endpoint
- batch & serverless === not persistant endpoint
- after mounting fs on sm training instance you can upload data on it
- redshift dynamic masking feature for PII - while query time - to user/role 
- validation:error for classification problems= error rate in predicted classes
 - xgboost -== supervised
- ss = autonomous vehicles to identify road signs and medical imaging to segment anatomical structures.
- kafka = ingesting and transporting streaming data.- You write producer and consumer apps to interact with it.
- Flink =  real-time streamdata processing, analytics, filtering, transformations, and aggregations.
- kullback - comparing distribution between outcome, tvd = maximum distance between outcome distribution
- AWS DataSync is an online tool for data transfer b/w on-premises storage and AWS services
- AWS Global Accelerator -  accelerating traffic to specific application endpoints like EC2 instances or
Elastic Load Balancers- improving the availability and performance of applications
- Route 53 - route traffic to nearest host of given application/model 
- codebuild = compiles source code, runs tests, and produces software packages
- online feature store = for inference
- offline feature store = for training & exploration
- S3 → EventBridge → Step Functions	
- S3 → Lambda → Step Functions
- Lambda will trigger sm processing job
- check feature contribution => shapley value = ModelExplainabilityMonitor 
- SHAP baselines = create an explainability baseline for = 'feature attribution' to the model’s predictions.
- howmuch outcome distribution b/w two group - kulback - diverge from each other   
- maximum/total outcome distribution b/w two group - TVD
- Kolmogorov-Smirnov (KS) = maximum / greatest disparities by demographic group
- step fun =  triggering the SageMaker Processing jobs for preprocessing, managing the data flow between different steps, 
and potentially invoking other AWS services like SageMaker Training for model training. 
- cw log insights = log analysis
- config = configuration drift and compliance status
- Identity-Based Policies: IAM users, groups, or roles
- SCPs = guardrails or limits on actions a user or role can do.
- sm studio has = monitor, wrangler ---- all features
- cross account IAM role --- specify other accnt arn in enabled policy statement
- assume this role using the sts:AssumeRole permission.
- SageMaker notebook instance is associated with a private subnet and has access to the VPC endpoint.
for accessing other services like comprehend
- cw log - monitoring and logging application-level events - running applications or AWS services
- to share model in canvas it should be registered in registery. 
- to train/deploy model put it in ECR
- Parquet format will not work for realtime processsing - it is columnar so batch processing can go
- Unstructured data ==== XXXXXXXX ==== not use Parquet
- unstructured data ===== jsonlines
- in loan context - customer demographic inf = age, income stat, marital stat, education level, employment etc
- transport layer - distributed training = inter container traffic = TLS layer encryption
- vector db will store only vector info, actual doc in knowledge base. Bedrock automatic manage update is kb update
- Transformer architecture is widely used to generate embeddings of text
- Diffusion arch - forward diffusion & reverse diffusion
- Sm Hyperpod = to distribute training data in smaller chunk to do parallel processing across accelerator
- online predictio  = immidiate check if transaction is fraudulent 
- Chi-square - determine whether = relationship between cate
gorical variables
- Amazon Q = Amazon Q Business + Amazon Q Developer ===== Amazon Q – Generative AI Assistant
- aws chatbot = slack, chime = run cmmand in slack, interact with aws service like cw from chatbot send notif
- neptune db === graph, recommandation app
- AWS codestar ====(for model/app) == > - template based === develop + build +test + deploy === complete proj 
- aws codepipeline === build + test + deploy === ci/cd
- Pruning	Reduces the size of a neural network by removing less important weights or neurons
  Reducing model complexity and size
- Quantization	Reduces the precision of the weights/activations in the model
  Speed and memory optimization, especially for inference
(e.g., from 32-bit floats to 8-bit integers) to reduce memory and improve speed.
Bayesian optimization
- Explores: Starts by sampling randomly or evenly across the search space.
- Exploits: Gradually focuses on regions where earlier trials performed well.





